---
title: "Plotting clustering trees"
author: "Luke Zappia"
date: "`r Sys.Date()`"
output:
    rmarkdown::html_vignette:
        fig_width: 7
        fig_height: 8.5
        fig_align: "center" 
vignette: >
  %\VignetteIndexEntry{Plotting clustering trees}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# What is a clustering tree?
 
Clustering analysis is used in many contexts to group similar samples. One
problem when conducting this kind of analysis is how many clusters to use. This
is usually controlled by a parameter provided to the clustering algorithm, such
as $k$ for $k$-means clustering.

Statistics designed to help you make this choice typically either compare two
clusterings or score a single clustering. A clustering tree is different in that
it visualises the relationships between at a range of resolutions.

To build a clustering tree we need to look at how cells move as the clustering
resolution is increased. Each cluster forms a node in the tree and edges are
constructed by considering the cells in a cluster at a lower resolution
(say $k = 2$) that end up in a cluster at the next highest resolution
(say $k = 3$). By connecting clusters in this way we can see how clusters are
related to each other, which are clearly distinct and which are unstable. Extra
information about the cells in each node can also be overlaid in order to help
make the decision about which resolution to use.

# A simple example

To demonstrate what a clustering tree looks like we will work through a short
example using the well known `iris` dataset.

## The data

The `iris` dataset consists of measurements (sepal length, sepal width, petal
length and petal width) of 150 iris flowers, 50 from each of three species
(_Iris setosa_, _Iris versicolor_ and _Iris virginica_). For more inforation see
`?iris`. We are going to use a version of this dataset that has already been 
clustered. Let's load the data and take a look:

```{r load-iris}
library(clustree)
data("iris_clusts")

head(iris_clusts)
```

Here we have a `data.frame` with the normal `iris` datasets, the measurements and 
species, plus some additional columns. These columns contain the cluster
assignments from clustering this data using $k$-means with values ok $k$ from
$k = 1$ to $k = 5$.

## Plotting a tree

This clustering information is all we need to build a clustering tree. Each
column must consist of numeric values indicating which cluster each sample
has been assigned to. To plot the tree we just pass this information to the
`clustree` function. We also need to specify and `prefix` string to indicate
which columns contain the clusterings.

```{r iris-plot}
clustree(iris_clusts, prefix = "K")
```

We can see that one cluster is very distinct and does not change with the value
of $k$. This is the _Iris setosa_ samples which are very different to the other
species. On the other side of the tree we see a single cluster that splits
into the two clusters we would expect to see. After this the tree becomes
messier and there are node with multiple incoming edges. This is a good 
indication that we have over clustered the data.

## Controlling aesthetics

By default the size of each node is related to the number of samples in each
cluster and the colour indicates the clustering resolution. Edges are coloured
according to the number of samples they represent and the transparency shows
the incoming node proportion, the number of samples in the edge divided by the
number of samples in the node it points to. We can control these aesthetics
by setting them to specific values:

```{r iris-aes-static}
clustree(iris_clusts, prefix = "K", node_colour = "purple", node_size = 10,
         node_alpha = 0.8)
```

We can also link these aesthetics to other information we have about the 
samples. All the additional columns in the dataset are available to be added as 
attributes to the nodes in our tree. Because each node represents multiple
samples as well specifying a column name we need to supply an aggregation
function to use. Let's try colouring the nodes according to the sepal width:

```{r iris-aes}
clustree(iris_clusts, prefix = "K", node_colour = "Sepal.Width",
         node_colour_aggr = "mean")
```

We can clearly see that the distinct cluster containing the _Iris setosa_
samples has a wider sepal on average compared to the other clusters.

## Layout

By default the tree is drawn using the Reingold-Tilford tree layout algorithm
which tries to place nodes below their parents. Alternatively we could use the
Sugiyama layout by specifying the `layout` argument. This algorithm tries to
minimise the number of crossing edges and can produce more attractive trees in
some cases.

```{r iris-layout}
clustree(iris_clusts, prefix = "K", layout = "sugiyama")
```

# Clustering trees for scRNA-seq data

Clustering has become a core tool for analysing single-cell RNA-sequencing
(scRNA-seq) datasets. These datasets contain gene expression measurements from
hundreds to hundreds of thousands of cells. Often samples come from complex
tissues containing many types of cells and clustering is used to group similar
cells together. To make it easier to produce clustering trees for these kinds
of datasets we provide interfaces for some of the objects commonly used to
analyse scRNA-seq data.

## SingleCellExperiment

The `SingleCellExperiment` is one of these common objects, used across a range
of Bioconductor packages. Let's have a look at an example:

```{r sim_sc3}
library("SingleCellExperiment")

data("sim_sc3")
sim_sc3
```

This is an example simulated scRNA-seq dataset in `SingleCellExperiment` format
that has been clustered using the `SC3` package. For more details about this
dataset and how it was produced see `?sim_sc3`. The clustering information
is held in the `coldata` slot.

```{r sim_sc3-colData}
head(colData(sim_sc3))
```

We can plot a clustering tree in the same way we did with a `data.frame`. In
this case the clustering column names contain a suffix that needs to be stripped
away so we will pass that along as well.

```{r sim_sc3-plot}
clustree(sim_sc3, prefix = "sc3_", suffix = "_clusters")
```

## Seurat

The same dataset is also available as `seurat` object that has been clustered
using the `Seurat` package. See `?sim_seurat` for details.

```{r sim_seurat}
library("Seurat")

data("sim_seurat")
sim_seurat
```

In this case the clustering information is held in the `meta.data` slot:

```{r sim_seurat-meta}
head(sim_seurat@meta.data)
```

Because this object is only used by the `Seurat` package we can assume the
prefix of the clustering columns.

```{r sim_seurat-plot}
clustree(sim_seurat)
```

## Using genes as aesthetics

As well as being able to use any additional columns for aesthetics we can also
use the expression of individual genes. Let's colour the nodes in the `Seurat`
tree by `Gene1`. Again we need to supply an aggregation function.

```{r plot-gene}
clustree(sim_seurat, node_colour = "Gene5", node_colour_aggr = "median")
```

# Modifying appearence

The `clustree` function returns a `ggplot` object which can be modified using
functions in the `ggplot2` or `ggraph` packages. For example we could change
the colour scales used for the nodes and edges:

```{r modify}
clustree(iris_clusts, prefix = "K") +
    scale_color_brewer(palette = "Set1") +
    scale_edge_color_continuous(low = "blue", high = "red")
```

## Legends

The way `ggplot` objects is displayed is relative to the size of the plotting
window or output file. While the main plot will always fit sometimes legends
will be placed outside the visible area. One solution to this is to simply 
increase the size of the image. An alternative solution is to turn off some of
the legends, either by setting some of the aesthetics to static values or by
using the `guides` function. We could also move them to somewhere they might
fit better. For example let's remove the edge legends and move the rest
to the bottom:

```{r legends}
clustree(iris_clusts, prefix = "K") +
    guides(edge_colour = FALSE, edge_alpha = FALSE) +
    theme(legend.position = "bottom")
```

